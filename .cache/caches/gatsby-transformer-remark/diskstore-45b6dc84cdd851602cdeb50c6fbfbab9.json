{"expireTime":9007200833923288000,"key":"transformer-remark-markdown-html-ast-78b1d96b184f182eacf4dfd0651b8075-gatsby-remark-copy-linked-filesgatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-katexgatsby-remark-smartypants-","val":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Anonymization of data became a very trendy topic in recent years. It had been widely addressed by the data community due to its growing importance to all companies collecting personal and sensitive information. ","position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":1,"column":212,"offset":211}}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":1,"column":212,"offset":211}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"While structured data is standardized and relatively easy to anonymize, dealing with unstructured data is more tedious. There is no database schema that can be used to measure privacy risk. In this blog, I propose to use a named-entity recognition system (NER) to automatically detect textual confidential attributes such as identifiers, sensitive information, etc. In this case study, I will consider that these confidential information to be detected are disease names in medical diagnoses.","position":{"start":{"line":3,"column":1,"offset":213},"end":{"line":3,"column":493,"offset":705}}}],"position":{"start":{"line":3,"column":1,"offset":213},"end":{"line":3,"column":493,"offset":705}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Named-Entity Recognition","position":{"start":{"line":5,"column":3,"offset":709},"end":{"line":5,"column":27,"offset":733}}}],"position":{"start":{"line":5,"column":1,"offset":707},"end":{"line":5,"column":27,"offset":733}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Named-entity recognition (also known as entity identification) seeks to identify and classify words in an unstructured text into pre-defined categories.","position":{"start":{"line":7,"column":1,"offset":735},"end":{"line":7,"column":153,"offset":887}}}],"position":{"start":{"line":7,"column":1,"offset":735},"end":{"line":7,"column":153,"offset":887}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"NER is a very challenging learning problem. On the one hand, Supervised training data is very scarce. On the other, this task requires language specific knowledge to construct efficient structured features.","position":{"start":{"line":9,"column":1,"offset":889},"end":{"line":9,"column":207,"offset":1095}}}],"position":{"start":{"line":9,"column":1,"offset":889},"end":{"line":9,"column":207,"offset":1095}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":" In our example, we are looking to anonymize medical diagnoses reports by identifying disease names. Thus, our problem is equivalent to a binary classification of names.","position":{"start":{"line":11,"column":1,"offset":1097},"end":{"line":11,"column":170,"offset":1266}}}],"position":{"start":{"line":11,"column":1,"offset":1097},"end":{"line":11,"column":170,"offset":1266}}},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Example : ","position":{"start":{"line":13,"column":3,"offset":1270},"end":{"line":13,"column":13,"offset":1280}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Testicular cancer ** and **endometriosis","position":{"start":{"line":13,"column":15,"offset":1282},"end":{"line":13,"column":55,"offset":1322}}}],"position":{"start":{"line":13,"column":13,"offset":1280},"end":{"line":13,"column":57,"offset":1324}}},{"type":"text","value":"  have increased in incidence during the last decades .","position":{"start":{"line":13,"column":57,"offset":1324},"end":{"line":13,"column":112,"offset":1379}}}],"position":{"start":{"line":13,"column":3,"offset":1270},"end":{"line":13,"column":112,"offset":1379}}},{"type":"text","value":"\n"}],"position":{"start":{"line":13,"column":1,"offset":1268},"end":{"line":13,"column":112,"offset":1379}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Methodology","position":{"start":{"line":17,"column":3,"offset":1385},"end":{"line":17,"column":14,"offset":1396}}}],"position":{"start":{"line":17,"column":1,"offset":1383},"end":{"line":17,"column":14,"offset":1396}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/images/uploads/blog2020/methodo.png","alt":"method"},"children":[],"position":{"start":{"line":19,"column":1,"offset":1398},"end":{"line":19,"column":48,"offset":1445}}}],"position":{"start":{"line":19,"column":1,"offset":1398},"end":{"line":19,"column":48,"offset":1445}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"As proof of concept, We will be focusing on locating disease names in medical reports using a model based on conditional random fields. ","position":{"start":{"line":21,"column":1,"offset":1447},"end":{"line":21,"column":137,"offset":1583}}}],"position":{"start":{"line":21,"column":1,"offset":1447},"end":{"line":21,"column":137,"offset":1583}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In practice, given a sentence, the model will tag each word with a ","position":{"start":{"line":23,"column":1,"offset":1585},"end":{"line":23,"column":68,"offset":1652}}},{"type":"raw","value":"<code class=\"language-text\">&quot;DISEASE&quot;</code>","position":{"start":{"line":23,"column":68,"offset":1652},"end":{"line":23,"column":80,"offset":1664}}},{"type":"text","value":" tag if it is a disease name and ","position":{"start":{"line":23,"column":80,"offset":1664},"end":{"line":23,"column":113,"offset":1697}}},{"type":"raw","value":"<code class=\"language-text\">&quot;O&quot;</code>","position":{"start":{"line":23,"column":113,"offset":1697},"end":{"line":23,"column":120,"offset":1704}}},{"type":"text","value":" tag otherwise,  which indicates that a token belongs to no chunk (outside).","position":{"start":{"line":23,"column":120,"offset":1704},"end":{"line":23,"column":196,"offset":1780}}}],"position":{"start":{"line":23,"column":1,"offset":1585},"end":{"line":23,"column":196,"offset":1780}}},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"First, we load the labeled data, which is a list of sentences and their corresponding labels","position":{"start":{"line":25,"column":4,"offset":1785},"end":{"line":25,"column":96,"offset":1877}}}],"position":{"start":{"line":25,"column":1,"offset":1782},"end":{"line":25,"column":96,"offset":1877}}},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"The second step is the tokenizer, which splits sentences into tokens","position":{"start":{"line":26,"column":4,"offset":1881},"end":{"line":26,"column":72,"offset":1949}}}],"position":{"start":{"line":26,"column":1,"offset":1878},"end":{"line":26,"column":72,"offset":1949}}},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"We use a feature generator to extract reliable features with a window of 3 words (the current word, the previous and the next words)","position":{"start":{"line":27,"column":4,"offset":1953},"end":{"line":27,"column":136,"offset":2085}}}],"position":{"start":{"line":27,"column":1,"offset":1950},"end":{"line":27,"column":136,"offset":2085}}},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"The final step uses a CRFs to train a NER model.","position":{"start":{"line":28,"column":4,"offset":2089},"end":{"line":28,"column":52,"offset":2137}}}],"position":{"start":{"line":28,"column":1,"offset":2086},"end":{"line":28,"column":52,"offset":2137}}},{"type":"text","value":"\n"}],"position":{"start":{"line":25,"column":1,"offset":1782},"end":{"line":28,"column":52,"offset":2137}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Training Data","position":{"start":{"line":30,"column":3,"offset":2141},"end":{"line":30,"column":16,"offset":2154}}}],"position":{"start":{"line":30,"column":1,"offset":2139},"end":{"line":30,"column":16,"offset":2154}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In our experiments, we took advantage of medical texts that were labeled to study the semantic relationships between diseases and treatments. These ","position":{"start":{"line":32,"column":1,"offset":2156},"end":{"line":32,"column":149,"offset":2304}}},{"type":"element","tagName":"a","properties":{"href":"https://biotext.berkeley.edu/dis_treat_data.html"},"children":[{"type":"text","value":"files","position":{"start":{"line":32,"column":150,"offset":2305},"end":{"line":32,"column":155,"offset":2310}}}],"position":{"start":{"line":32,"column":149,"offset":2304},"end":{"line":32,"column":206,"offset":2361}}},{"type":"text","value":" were obtained from MEDLINE 2001 using the first 100 titles and the first 40 abstracts from the 59 files medline01n*.xml. These data contain 3,654 labeled sentences. The labels are: ”DISONLY”, ”TREATONLY”, ”TREAT PREV”, ”DIS PREV”, ”TREAT SIDE EFF”, ”DIS SIDE EFF”, ”DIS VAG”, ”TREAT VAG”, ”TREAT NO” and ”DIS NO”. Because we were only interested in diseases, we only used the 629 sentences with the ”DISONLY” label.","position":{"start":{"line":32,"column":206,"offset":2361},"end":{"line":32,"column":622,"offset":2777}}}],"position":{"start":{"line":32,"column":1,"offset":2156},"end":{"line":32,"column":622,"offset":2777}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"After formatting and tokenizing raw text data, it looks like this :","position":{"start":{"line":34,"column":1,"offset":2779},"end":{"line":34,"column":68,"offset":2846}}}],"position":{"start":{"line":34,"column":1,"offset":2779},"end":{"line":34,"column":68,"offset":2846}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> random\n<span class=\"token keyword\">from</span> spacy<span class=\"token punctuation\">.</span>tokenizer <span class=\"token keyword\">import</span> Tokenizer\n<span class=\"token keyword\">from</span> spacy<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>en <span class=\"token keyword\">import</span> English\nnlp <span class=\"token operator\">=</span> English<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Create a blank Tokenizer with just the English vocab</span>\ntokenizer <span class=\"token operator\">=</span> Tokenizer<span class=\"token punctuation\">(</span>nlp<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">)</span>\nfilepath <span class=\"token operator\">=</span> <span class=\"token string\">'data/sentences_with_roles_and_relations.txt'</span>\ndisease_data <span class=\"token operator\">=</span> read_text_labeled_sentences<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> tokenizer<span class=\"token punctuation\">)</span>\nsample_data_point <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>choice<span class=\"token punctuation\">(</span>disease_data<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Tokens:\\n {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>sample_data_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Labels:\\n {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>sample_data_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>","position":{"start":{"line":36,"column":1,"offset":2848},"end":{"line":49,"column":4,"offset":3323}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Out:","position":{"start":{"line":51,"column":1,"offset":3325},"end":{"line":51,"column":5,"offset":3329}}}],"position":{"start":{"line":51,"column":1,"offset":3325},"end":{"line":51,"column":5,"offset":3329}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/images/uploads/blog2020/input_data.png","alt":"method"},"children":[],"position":{"start":{"line":53,"column":1,"offset":3331},"end":{"line":53,"column":51,"offset":3381}}}],"position":{"start":{"line":53,"column":1,"offset":3331},"end":{"line":53,"column":51,"offset":3381}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"So basically, disease data is a list of tuples, each tuple (tokens, labels) represent a sentence divided into tokens and corresponding labels. Where 1 stands for disease name and 0 for other than disease names.","position":{"start":{"line":55,"column":1,"offset":3383},"end":{"line":55,"column":211,"offset":3593}}}],"position":{"start":{"line":55,"column":1,"offset":3383},"end":{"line":55,"column":211,"offset":3593}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The disease name in the example above  is “head-neck carcinomas”. Thus, the last 2 labels are both equal to 1.","position":{"start":{"line":57,"column":1,"offset":3595},"end":{"line":57,"column":111,"offset":3705}}}],"position":{"start":{"line":57,"column":1,"offset":3595},"end":{"line":57,"column":111,"offset":3705}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Conditional Random Fields","position":{"start":{"line":59,"column":3,"offset":3709},"end":{"line":59,"column":28,"offset":3734}}}],"position":{"start":{"line":59,"column":1,"offset":3707},"end":{"line":59,"column":28,"offset":3734}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"CRFs have seen wide application in many areas, including natural language processing and computer vision. They are often used for structured prediction and tasks that require predicting variables that depend on each other as well as on observed variables.  ","position":{"start":{"line":61,"column":1,"offset":3736},"end":{"line":61,"column":258,"offset":3993}}}],"position":{"start":{"line":61,"column":1,"offset":3736},"end":{"line":61,"column":258,"offset":3993}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"CRFs models combine the ability of graphical models to compactly model the dependence between multivariate data and the ability of classification methods to predict outputs using large sets of input features. ","position":{"start":{"line":63,"column":1,"offset":3995},"end":{"line":63,"column":210,"offset":4204}}}],"position":{"start":{"line":63,"column":1,"offset":3995},"end":{"line":63,"column":210,"offset":4204}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"These models are considered to be the discriminative equivalents of the hidden Markov models. But first, let’s explain what is the difference between generative and discriminative models.","position":{"start":{"line":65,"column":1,"offset":4206},"end":{"line":65,"column":188,"offset":4393}}}],"position":{"start":{"line":65,"column":1,"offset":4206},"end":{"line":65,"column":188,"offset":4393}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h4","properties":{},"children":[{"type":"text","value":"Generative and Discriminative Models","position":{"start":{"line":67,"column":6,"offset":4400},"end":{"line":67,"column":42,"offset":4436}}}],"position":{"start":{"line":67,"column":1,"offset":4395},"end":{"line":67,"column":42,"offset":4436}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Generative models’ approach might seem counterintuitive. They describe how a target vector y (type of words in our case) can probabilistically “generate” a feature vector x (words in our case). Discriminative models are more intuitive because they are working backward, they describe how to assign a label y to a feature vector x.","position":{"start":{"line":69,"column":1,"offset":4438},"end":{"line":69,"column":331,"offset":4768}}}],"position":{"start":{"line":69,"column":1,"offset":4438},"end":{"line":69,"column":331,"offset":4768}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In principle, we can see that the approaches are distinct. They work in two opposite directions,  but theoretically, we can always convert between the two methods using Bayes rule.","position":{"start":{"line":71,"column":1,"offset":4770},"end":{"line":71,"column":181,"offset":4950}}}],"position":{"start":{"line":71,"column":1,"offset":4770},"end":{"line":71,"column":181,"offset":4950}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"For example, in the naive Bayes model, it is easy to convert the joint probability ","position":{"start":{"line":73,"column":1,"offset":4952},"end":{"line":73,"column":84,"offset":5035}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"p(x,y) = p(y)p(x/y)","position":{"start":{"line":73,"column":86,"offset":5037},"end":{"line":73,"column":105,"offset":5056}}}],"position":{"start":{"line":73,"column":84,"offset":5035},"end":{"line":73,"column":107,"offset":5058}}},{"type":"text","value":" into a conditional distribution ","position":{"start":{"line":73,"column":107,"offset":5058},"end":{"line":73,"column":140,"offset":5091}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"p(y/x)","position":{"start":{"line":73,"column":142,"offset":5093},"end":{"line":73,"column":148,"offset":5099}}}],"position":{"start":{"line":73,"column":140,"offset":5091},"end":{"line":73,"column":150,"offset":5101}}},{"type":"text","value":". But in practice, we never have the exact true distribution to calculate the conditional distribution. We can end up with two different estimations of p(y/x).","position":{"start":{"line":73,"column":150,"offset":5101},"end":{"line":73,"column":309,"offset":5260}}}],"position":{"start":{"line":73,"column":1,"offset":4952},"end":{"line":73,"column":309,"offset":5260}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"To sum up, Generative and discriminative may have the same purpose which is calculating the conditional probability p(y/x), but they proceed in two different ways.","position":{"start":{"line":75,"column":1,"offset":5262},"end":{"line":75,"column":164,"offset":5425}}}],"position":{"start":{"line":75,"column":1,"offset":5262},"end":{"line":75,"column":164,"offset":5425}}},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The difference between generative models and CRFs is exactly analogous to the difference between the naive Bayes and logistic regression classifiers.","position":{"start":{"line":77,"column":3,"offset":5429},"end":{"line":77,"column":152,"offset":5578}}}],"position":{"start":{"line":77,"column":3,"offset":5429},"end":{"line":77,"column":152,"offset":5578}}},{"type":"text","value":"\n"}],"position":{"start":{"line":77,"column":1,"offset":5427},"end":{"line":77,"column":152,"offset":5578}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"CRFs methods can be seen as the discriminative analog of  generative Hidden Markov models. They can also be understood as a generalization of the logistic regression classifier to arbitrary graphical structures.","position":{"start":{"line":79,"column":1,"offset":5580},"end":{"line":79,"column":212,"offset":5791}}}],"position":{"start":{"line":79,"column":1,"offset":5580},"end":{"line":79,"column":212,"offset":5791}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Since our named-entity recognition task relies on predicting labels based on context and not only on each word’s features, CRFs methods might be a good choice to begin with.","position":{"start":{"line":81,"column":1,"offset":5793},"end":{"line":81,"column":174,"offset":5966}}}],"position":{"start":{"line":81,"column":1,"offset":5793},"end":{"line":81,"column":174,"offset":5966}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We will try in the next section ton implement CRFs methods using ","position":{"start":{"line":83,"column":1,"offset":5968},"end":{"line":83,"column":66,"offset":6033}}},{"type":"element","tagName":"a","properties":{"href":"https://python-crfsuite.readthedocs.io/en/latest/"},"children":[{"type":"text","value":"pycrfsuite","position":{"start":{"line":83,"column":67,"offset":6034},"end":{"line":83,"column":77,"offset":6044}}}],"position":{"start":{"line":83,"column":66,"offset":6033},"end":{"line":83,"column":129,"offset":6096}}},{"type":"text","value":".","position":{"start":{"line":83,"column":129,"offset":6096},"end":{"line":83,"column":130,"offset":6097}}}],"position":{"start":{"line":83,"column":1,"offset":5968},"end":{"line":83,"column":130,"offset":6097}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h4","properties":{},"children":[{"type":"text","value":"Implementation","position":{"start":{"line":85,"column":6,"offset":6104},"end":{"line":85,"column":20,"offset":6118}}}],"position":{"start":{"line":85,"column":1,"offset":6099},"end":{"line":85,"column":20,"offset":6118}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Now that we explained the motivation behind using CRFs model for Named Entity recognition, let’s dive directly into code.","position":{"start":{"line":87,"column":1,"offset":6120},"end":{"line":87,"column":122,"offset":6241}}}],"position":{"start":{"line":87,"column":1,"offset":6120},"end":{"line":87,"column":122,"offset":6241}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"First, we begin by calculating features for each word with a window of 3 words, which means that we also include features of next and previous words.","position":{"start":{"line":89,"column":1,"offset":6243},"end":{"line":89,"column":150,"offset":6392}}}],"position":{"start":{"line":89,"column":1,"offset":6243},"end":{"line":89,"column":150,"offset":6392}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Here, we calculate features like word parts, POS tags, word dependencies, lemma, shape (the shape of the word, example: “CRFs” -> “XXXx”), and other boolean variables like isupper (check if characters are in uppercase), istitle (check if the first character is in uppercase), isdigit (check whether the word consists of digits only), is_stop (check whether the word is a stop word), etc.","position":{"start":{"line":91,"column":1,"offset":6394},"end":{"line":91,"column":388,"offset":6781}}}],"position":{"start":{"line":91,"column":1,"offset":6394},"end":{"line":91,"column":388,"offset":6781}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Sklearn-crfsuite supports several input formats; here we use feature lists.","position":{"start":{"line":93,"column":1,"offset":6783},"end":{"line":93,"column":76,"offset":6858}}}],"position":{"start":{"line":93,"column":1,"offset":6783},"end":{"line":93,"column":76,"offset":6858}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The code below was adapted from the ","position":{"start":{"line":95,"column":1,"offset":6860},"end":{"line":95,"column":37,"offset":6896}}},{"type":"element","tagName":"a","properties":{"href":"https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html"},"children":[{"type":"text","value":"official documentation","position":{"start":{"line":95,"column":38,"offset":6897},"end":{"line":95,"column":60,"offset":6919}}}],"position":{"start":{"line":95,"column":37,"offset":6896},"end":{"line":95,"column":126,"offset":6985}}}],"position":{"start":{"line":95,"column":1,"offset":6860},"end":{"line":95,"column":126,"offset":6985}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> random\n<span class=\"token keyword\">import</span> pycrfsuite\n<span class=\"token keyword\">def</span> <span class=\"token function\">word2features</span><span class=\"token punctuation\">(</span>train_sample<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    token <span class=\"token operator\">=</span> train_sample<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n    word <span class=\"token operator\">=</span> token<span class=\"token punctuation\">.</span>text\n    features <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">'bias'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.lower='</span> <span class=\"token operator\">+</span> word<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word[-3:]='</span> <span class=\"token operator\">+</span> word<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word[-2:]='</span> <span class=\"token operator\">+</span> word<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.isupper=%s'</span> <span class=\"token operator\">%</span> word<span class=\"token punctuation\">.</span>isupper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.istitle=%s'</span> <span class=\"token operator\">%</span> word<span class=\"token punctuation\">.</span>istitle<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.isdigit=%s'</span> <span class=\"token operator\">%</span> word<span class=\"token punctuation\">.</span>isdigit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.pos='</span><span class=\"token operator\">+</span>token<span class=\"token punctuation\">.</span>pos_<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.dep='</span><span class=\"token operator\">+</span>token<span class=\"token punctuation\">.</span>dep_<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.is_stop=%s'</span> <span class=\"token operator\">%</span>token<span class=\"token punctuation\">.</span>is_stop<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.lemma='</span> <span class=\"token operator\">+</span> token<span class=\"token punctuation\">.</span>lemma_<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.tag='</span> <span class=\"token operator\">+</span> token<span class=\"token punctuation\">.</span>tag_<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.shape='</span> <span class=\"token operator\">+</span> token<span class=\"token punctuation\">.</span>shape_<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'word.is_alpha=%s'</span> <span class=\"token operator\">%</span>token<span class=\"token punctuation\">.</span>is_alpha<span class=\"token punctuation\">,</span>        \n    <span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">if</span> i <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        token1 <span class=\"token operator\">=</span> train_sample<span class=\"token punctuation\">[</span>i<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n        word1 <span class=\"token operator\">=</span> token1<span class=\"token punctuation\">.</span>text\n        features<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">'-1:word.lower='</span> <span class=\"token operator\">+</span> word1<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.istitle=%s'</span> <span class=\"token operator\">%</span> word1<span class=\"token punctuation\">.</span>istitle<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.isupper=%s'</span> <span class=\"token operator\">%</span> word1<span class=\"token punctuation\">.</span>isupper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.pos='</span><span class=\"token operator\">+</span>token1<span class=\"token punctuation\">.</span>pos_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.dep='</span><span class=\"token operator\">+</span>token1<span class=\"token punctuation\">.</span>dep_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.is_stop=%s'</span> <span class=\"token operator\">%</span>token1<span class=\"token punctuation\">.</span>is_stop<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.lemma='</span> <span class=\"token operator\">+</span> token1<span class=\"token punctuation\">.</span>lemma_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.tag='</span> <span class=\"token operator\">+</span> token1<span class=\"token punctuation\">.</span>tag_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.shape='</span> <span class=\"token operator\">+</span> token1<span class=\"token punctuation\">.</span>shape_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'-1:word.is_alpha=%s'</span> <span class=\"token operator\">%</span>token1<span class=\"token punctuation\">.</span>is_alpha<span class=\"token punctuation\">,</span>    \n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        features<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'BOS'</span><span class=\"token punctuation\">)</span>\n        \n    <span class=\"token keyword\">if</span> i <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_sample<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n        token1 <span class=\"token operator\">=</span> train_sample<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n        word1 <span class=\"token operator\">=</span> token1<span class=\"token punctuation\">.</span>text\n        features<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">'+1:word.lower='</span> <span class=\"token operator\">+</span> word1<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.istitle=%s'</span> <span class=\"token operator\">%</span> word1<span class=\"token punctuation\">.</span>istitle<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.isupper=%s'</span> <span class=\"token operator\">%</span> word1<span class=\"token punctuation\">.</span>isupper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.pos='</span><span class=\"token operator\">+</span>token1<span class=\"token punctuation\">.</span>pos_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.dep='</span><span class=\"token operator\">+</span>token1<span class=\"token punctuation\">.</span>dep_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.is_stop=%s'</span> <span class=\"token operator\">%</span>token1<span class=\"token punctuation\">.</span>is_stop<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.lemma='</span> <span class=\"token operator\">+</span> token1<span class=\"token punctuation\">.</span>lemma_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.tag='</span> <span class=\"token operator\">+</span> token1<span class=\"token punctuation\">.</span>tag_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.shape='</span> <span class=\"token operator\">+</span> token1<span class=\"token punctuation\">.</span>shape_<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'+1:word.is_alpha=%s'</span> <span class=\"token operator\">%</span>token1<span class=\"token punctuation\">.</span>is_alpha<span class=\"token punctuation\">,</span>   \n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        features<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'EOS'</span><span class=\"token punctuation\">)</span>       \n    <span class=\"token keyword\">return</span> features\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">sent2features</span><span class=\"token punctuation\">(</span>train_sample<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>word2features<span class=\"token punctuation\">(</span>train_sample<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_sample<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">encode_labels</span><span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"DISEASE\"</span> <span class=\"token keyword\">if</span> label<span class=\"token operator\">==</span><span class=\"token number\">1</span> <span class=\"token keyword\">else</span> <span class=\"token string\">\"O\"</span> <span class=\"token keyword\">for</span> label <span class=\"token keyword\">in</span> labels<span class=\"token punctuation\">]</span></code></pre></div>","position":{"start":{"line":99,"column":1,"offset":6989},"end":{"line":163,"column":4,"offset":9172}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We use the encode_labels function to encode integer labels (0 or 1) to string labels (“DISEASE” or “O”) to respect the target format needed by Sklearn-crfsuite.","position":{"start":{"line":165,"column":1,"offset":9174},"end":{"line":165,"column":161,"offset":9334}}}],"position":{"start":{"line":165,"column":1,"offset":9174},"end":{"line":165,"column":161,"offset":9334}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">random<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>disease_data<span class=\"token punctuation\">)</span>\ntraining_data <span class=\"token operator\">=</span> disease_data<span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.3</span><span class=\"token operator\">*</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>disease_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\ntest_data <span class=\"token operator\">=</span> disease_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.3</span><span class=\"token operator\">*</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>disease_data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\">#%%</span>\nX_train <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>sent2features<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> training_data<span class=\"token punctuation\">]</span>\ny_train <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>encode_labels<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> training_data<span class=\"token punctuation\">]</span>\n\nX_test <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>sent2features<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> test_data<span class=\"token punctuation\">]</span>\ny_test <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> test_data<span class=\"token punctuation\">]</span></code></pre></div>","position":{"start":{"line":167,"column":1,"offset":9336},"end":{"line":177,"column":4,"offset":9690}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Once we defined the training and the test sets, we can begin training the model.","position":{"start":{"line":179,"column":1,"offset":9692},"end":{"line":179,"column":81,"offset":9772}}}],"position":{"start":{"line":179,"column":1,"offset":9692},"end":{"line":179,"column":81,"offset":9772}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">trainer <span class=\"token operator\">=</span> pycrfsuite<span class=\"token punctuation\">.</span>Trainer<span class=\"token punctuation\">(</span>verbose<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> xseq<span class=\"token punctuation\">,</span> yseq <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    trainer<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>xseq<span class=\"token punctuation\">,</span> yseq<span class=\"token punctuation\">)</span>\n\ntrainer<span class=\"token punctuation\">.</span>set_params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n    <span class=\"token string\">'c1'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.44</span><span class=\"token punctuation\">,</span>   <span class=\"token comment\"># coefficient for L1 penalty</span>\n    <span class=\"token string\">'c2'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># coefficient for L2 penalty</span>\n    <span class=\"token string\">'max_iterations'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">60</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># stop earlier</span>\n\n    <span class=\"token comment\"># include transitions that are possible, but not observed</span>\n    <span class=\"token string\">'feature.possible_transitions'</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">True</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Model's parameters : {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>trainer<span class=\"token punctuation\">.</span>params<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntrainer<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token string\">'models/crf_model.crfsuite'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Last iteration log {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>trainer<span class=\"token punctuation\">.</span>logparser<span class=\"token punctuation\">.</span>last_iteration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>","position":{"start":{"line":181,"column":1,"offset":9774},"end":{"line":198,"column":4,"offset":10341}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Out:","position":{"start":{"line":200,"column":1,"offset":10343},"end":{"line":200,"column":5,"offset":10347}}}],"position":{"start":{"line":200,"column":1,"offset":10343},"end":{"line":200,"column":5,"offset":10347}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/images/uploads/blog2020/CRF_log.png","alt":"log"},"children":[],"position":{"start":{"line":202,"column":1,"offset":10349},"end":{"line":202,"column":45,"offset":10393}}}],"position":{"start":{"line":202,"column":1,"offset":10349},"end":{"line":202,"column":45,"offset":10393}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We begin by defining a trainer which is mainly our CRFs model, we then define some parameters like c1 and c2 (Coefficients used for regularization) and the max_iteration parameter (used to stop model’s iterations). After training, the model is automatically stored in the directory specified in the train function.","position":{"start":{"line":204,"column":1,"offset":10395},"end":{"line":204,"column":315,"offset":10709}}}],"position":{"start":{"line":204,"column":1,"offset":10395},"end":{"line":204,"column":315,"offset":10709}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Results and conclusion","position":{"start":{"line":206,"column":3,"offset":10713},"end":{"line":206,"column":25,"offset":10735}}}],"position":{"start":{"line":206,"column":1,"offset":10711},"end":{"line":206,"column":26,"offset":10736}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"After training the model, let’s see how to calculate the labels for a given test example:","position":{"start":{"line":208,"column":1,"offset":10738},"end":{"line":208,"column":90,"offset":10827}}}],"position":{"start":{"line":208,"column":1,"offset":10738},"end":{"line":208,"column":90,"offset":10827}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tagger <span class=\"token operator\">=</span> pycrfsuite<span class=\"token punctuation\">.</span>Tagger<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntagger<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"models/crf_model.crfsuite\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sentence: {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"predicted labels: {}\"</span><span class=\"token punctuation\">.</span> <span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>tagger<span class=\"token punctuation\">.</span>tag<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"real labels {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>encode_labels<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>","position":{"start":{"line":210,"column":1,"offset":10829},"end":{"line":218,"column":4,"offset":11078}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Out:","position":{"start":{"line":220,"column":1,"offset":11080},"end":{"line":220,"column":5,"offset":11084}}}],"position":{"start":{"line":220,"column":1,"offset":11080},"end":{"line":220,"column":5,"offset":11084}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/images/uploads/blog2020/output.png","alt":"output"},"children":[],"position":{"start":{"line":222,"column":1,"offset":11086},"end":{"line":222,"column":47,"offset":11132}}}],"position":{"start":{"line":222,"column":1,"offset":11086},"end":{"line":222,"column":47,"offset":11132}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"As we can see, the model predicts it right this time, but it may surely miss some disease names. Let’s measure the overall performance.","position":{"start":{"line":224,"column":1,"offset":11134},"end":{"line":224,"column":136,"offset":11269}}}],"position":{"start":{"line":224,"column":1,"offset":11134},"end":{"line":224,"column":136,"offset":11269}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">outputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    outputs<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>tagger<span class=\"token punctuation\">.</span>tag<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntargets <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\noutputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span> <span class=\"token keyword\">if</span> output<span class=\"token operator\">==</span><span class=\"token string\">\"O\"</span> <span class=\"token keyword\">else</span> <span class=\"token number\">1</span> <span class=\"token keyword\">for</span> output <span class=\"token keyword\">in</span> outputs<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"conf_matrix: \\n\"</span><span class=\"token punctuation\">,</span> confusion_matrix<span class=\"token punctuation\">(</span>targets<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"precision score:\\n\"</span><span class=\"token punctuation\">,</span> precision_score<span class=\"token punctuation\">(</span>targets<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"recall score:\\n\"</span><span class=\"token punctuation\">,</span> recall_score<span class=\"token punctuation\">(</span>targets<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"F1 score:\\n\"</span><span class=\"token punctuation\">,</span> f1_score<span class=\"token punctuation\">(</span>targets<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>","position":{"start":{"line":226,"column":1,"offset":11271},"end":{"line":239,"column":4,"offset":11711}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Out:","position":{"start":{"line":241,"column":1,"offset":11713},"end":{"line":241,"column":5,"offset":11717}}}],"position":{"start":{"line":241,"column":1,"offset":11713},"end":{"line":241,"column":5,"offset":11717}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/images/uploads/blog2020/measure.png","alt":"measure"},"children":[],"position":{"start":{"line":243,"column":1,"offset":11719},"end":{"line":243,"column":49,"offset":11767}}}],"position":{"start":{"line":243,"column":1,"offset":11719},"end":{"line":243,"column":49,"offset":11767}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We can see that the precision is much better than recall, which means that the number of false positives (Other names that are detected as disease names) is not that high. Still, there is a lot of disease names that are undetectable by the model. It might be explained by the size of the training dataset.","position":{"start":{"line":245,"column":1,"offset":11769},"end":{"line":245,"column":306,"offset":12074}}}],"position":{"start":{"line":245,"column":1,"offset":11769},"end":{"line":245,"column":306,"offset":12074}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"It is worth mentioning that this model is very sensitive to features choice. I recommend the reader to delete or add features of his choice to test the model.","position":{"start":{"line":247,"column":1,"offset":12076},"end":{"line":247,"column":159,"offset":12234}}}],"position":{"start":{"line":247,"column":1,"offset":12076},"end":{"line":247,"column":159,"offset":12234}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"CRFs are indeed well suited to named-entity recognition task, but other deep learning models have shown a better performance. For example, RNNs architectures are known to be able to capture the dependence between input variables. Some recent works also include contextual embedding of words using attention (BERT, XLNet, etc.) which might boost model’s performance.","position":{"start":{"line":249,"column":1,"offset":12236},"end":{"line":249,"column":366,"offset":12601}}}],"position":{"start":{"line":249,"column":1,"offset":12236},"end":{"line":249,"column":366,"offset":12601}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"So, that’s it for today, I hope it helped you understand how to apply NER task to text annonymization and how to implement your first CRFs model. Feel free to share the blog if you want to.","position":{"start":{"line":251,"column":1,"offset":12603},"end":{"line":251,"column":190,"offset":12792}}}],"position":{"start":{"line":251,"column":1,"offset":12603},"end":{"line":251,"column":190,"offset":12792}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"You can find full code in my ","position":{"start":{"line":253,"column":1,"offset":12794},"end":{"line":253,"column":30,"offset":12823}}},{"type":"element","tagName":"a","properties":{"href":"https://github.com/hamzamassaoudi/CRF_NER"},"children":[{"type":"text","value":"GitHub page","position":{"start":{"line":253,"column":31,"offset":12824},"end":{"line":253,"column":42,"offset":12835}}}],"position":{"start":{"line":253,"column":30,"offset":12823},"end":{"line":253,"column":86,"offset":12879}}}],"position":{"start":{"line":253,"column":1,"offset":12794},"end":{"line":253,"column":86,"offset":12879}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Reference","position":{"start":{"line":255,"column":3,"offset":12883},"end":{"line":255,"column":12,"offset":12892}}}],"position":{"start":{"line":255,"column":1,"offset":12881},"end":{"line":255,"column":12,"offset":12892}}},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://biotext.berkeley.edu/dis_treat_data.html"},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Classifying Semantic Relations in Bioscience Text","position":{"start":{"line":257,"column":6,"offset":12899},"end":{"line":257,"column":55,"offset":12948}}}],"position":{"start":{"line":257,"column":5,"offset":12898},"end":{"line":257,"column":56,"offset":12949}}},{"type":"text","value":", Barbara Rosario and Marti A. Hearst, in the proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), Barcelona, July 2004.","position":{"start":{"line":257,"column":56,"offset":12949},"end":{"line":257,"column":223,"offset":13116}}}],"position":{"start":{"line":257,"column":4,"offset":12897},"end":{"line":257,"column":274,"offset":13167}}}],"position":{"start":{"line":257,"column":1,"offset":12894},"end":{"line":257,"column":274,"offset":13167}}},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://sklearn-crfsuite.readthedocs.io/en/latest/index.html"},"children":[{"type":"text","value":"sklearn-crfsuite documentation","position":{"start":{"line":258,"column":5,"offset":13172},"end":{"line":258,"column":35,"offset":13202}}}],"position":{"start":{"line":258,"column":4,"offset":13171},"end":{"line":258,"column":98,"offset":13265}}}],"position":{"start":{"line":258,"column":1,"offset":13168},"end":{"line":258,"column":98,"offset":13265}}},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf"},"children":[{"type":"text","value":"An Introduction to Conditional Random Fields By Charles Sutton and Andrew McCallum","position":{"start":{"line":259,"column":5,"offset":13270},"end":{"line":259,"column":87,"offset":13352}}}],"position":{"start":{"line":259,"column":4,"offset":13269},"end":{"line":259,"column":156,"offset":13421}}}],"position":{"start":{"line":259,"column":1,"offset":13266},"end":{"line":259,"column":156,"offset":13421}}},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Anonymization of Unstructured Data Via Named-Entity Recognition by Fadi Hassan Et Al.","position":{"start":{"line":260,"column":4,"offset":13425},"end":{"line":260,"column":89,"offset":13510}}}],"position":{"start":{"line":260,"column":1,"offset":13422},"end":{"line":260,"column":89,"offset":13510}}},{"type":"text","value":"\n"}],"position":{"start":{"line":257,"column":1,"offset":12894},"end":{"line":260,"column":89,"offset":13510}}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":270,"column":2,"offset":13521}}}}